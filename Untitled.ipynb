{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a5389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <th>Magic</th>\n",
       "    <th>Example</th>\n",
       "    <th>Explanation</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>info</td>\n",
       "    <td>%%info</td>\n",
       "    <td>Outputs session information for the current Livy endpoint.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>cleanup</td>\n",
       "    <td>%%cleanup -f</td>\n",
       "    <td>Deletes all sessions for the current Livy endpoint, including this notebook's session. The force flag is mandatory.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>delete</td>\n",
       "    <td>%%delete -f -s 0</td>\n",
       "    <td>Deletes a session by number for the current Livy endpoint. Cannot delete this kernel's session.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>logs</td>\n",
       "    <td>%%logs</td>\n",
       "    <td>Outputs the current session's Livy logs.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>configure</td>\n",
       "    <td>%%configure -f<br/>{\"executorMemory\": \"1000M\", \"executorCores\": 4}</td>\n",
       "    <td>Configure the session creation parameters. The force flag is mandatory if a session has already been\n",
       "    created and the session will be dropped and recreated.<br/>Look at <a href=\"https://github.com/cloudera/livy#request-body\">\n",
       "    Livy's POST /sessions Request Body</a> for a list of valid parameters. Parameters must be passed in as a JSON string.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>spark</td>\n",
       "    <td>%%spark -o df<br/>df = spark.read.parquet('...</td>\n",
       "    <td>Executes spark commands.\n",
       "    Parameters:\n",
       "      <ul>\n",
       "        <li>-o VAR_NAME: The Spark dataframe of name VAR_NAME will be available in the %%local Python context as a\n",
       "          <a href=\"http://pandas.pydata.org/\">Pandas</a> dataframe with the same name.</li>\n",
       "        <li>-m METHOD: Sample method, either <tt>take</tt> or <tt>sample</tt>.</li>\n",
       "        <li>-n MAXROWS: The maximum number of rows of a dataframe that will be pulled from Livy to Jupyter.\n",
       "            If this number is negative, then the number of rows will be unlimited.</li>\n",
       "        <li>-r FRACTION: Fraction used for sampling.</li>\n",
       "      </ul>\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>sql</td>\n",
       "    <td>%%sql -o tables -q<br/>SHOW TABLES</td>\n",
       "    <td>Executes a SQL query against the variable sqlContext (Spark v1.x) or spark (Spark v2.x).\n",
       "    Parameters:\n",
       "      <ul>\n",
       "        <li>-o VAR_NAME: The result of the SQL query will be available in the %%local Python context as a\n",
       "          <a href=\"http://pandas.pydata.org/\">Pandas</a> dataframe.</li>\n",
       "        <li>-q: The magic will return None instead of the dataframe (no visualization).</li>\n",
       "        <li>-m, -n, -r are the same as the %%spark parameters above.</li>\n",
       "      </ul>\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>local</td>\n",
       "    <td>%%local<br/>a = 1</td>\n",
       "    <td>All the code in subsequent lines will be executed locally. Code must be valid Python code.</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>send_to_spark</td>\n",
       "    <td>%%send_to_spark -i variable -t str -n var</td>\n",
       "    <td>Sends a variable from local output to spark cluster.\n",
       "    <br/>\n",
       "    Parameters:\n",
       "      <ul>\n",
       "        <li>-i VAR_NAME: Local Pandas DataFrame(or String) of name VAR_NAME will be available in the %%spark context as a \n",
       "          Spark dataframe(or String) with the same name.</li>\n",
       "        <li>-t TYPE: Specifies the type of variable passed as -i. Available options are:\n",
       "         `str` for string and `df` for Pandas DataFrame. Optional, defaults to `str`.</li>\n",
       "        <li>-n NAME: Custom name of variable passed as -i. Optional, defaults to -i variable name.</li>\n",
       "        <li>-m MAXROWS: Maximum amount of Pandas rows that will be sent to Spark. Defaults to 2500.</li>\n",
       "      </ul>\n",
       "    </td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>pretty</td>\n",
       "    <td>%%pretty</td>\n",
       "    <td>If the cell output is a dataframe, like <code>df.show()</code>, then it will pretty print the dataframe as an HTML table</td>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a80deca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%configure is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4225540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "# Setup Spark Session & Begin using for Analysis\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, TimestampType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('01_analysis_nb') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "service_dta = spark.read.parquet('s3://takehome-process/2021-09-17/service_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553863e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-----------+-----------------+--------------------+----------------+--------------------+---------------------+-----------------+------------------+------------------+-----------------------+-----------------------+-----------------+---------+--------+------+--------+----------+-------+-----+----------------+---------------+------------+\n",
      "|        case_summary|   case_status|case_source|case_created_date|   case_created_dttm|case_closed_date|    case_closed_dttm|first_call_resolution|customer_zip_code|incident_address_1|incident_address_2|incident_intersection_1|incident_intersection_2|incident_zip_code|longitude|latitude|agency|division|major_area|   type|topic|council_district|police_district|neighborhood|\n",
      "+--------------------+--------------+-----------+-----------------+--------------------+----------------+--------------------+---------------------+-----------------+------------------+------------------+-----------------------+-----------------------+-----------------+---------+--------+------+--------+----------+-------+-----+----------------+---------------+------------+\n",
      "|311 - General Inq...|Closed - Other|      Phone|       10/07/2015|10/07/2015 11:54:...|      10/07/2015|10/07/2015 11:59:...|                    Y|            80003|              null|              null|                   null|                   null|             null|     null|    null|   311|    null|      null|Inquiry| null|            null|           null|        null|\n",
      "+--------------------+--------------+-----------+-----------------+--------------------+----------------+--------------------+---------------------+-----------------+------------------+------------------+-----------------------+-----------------------+-----------------+---------+--------+------+--------+----------+-------+-----+----------------+---------------+------------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "service_dta.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5bdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
